{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pulki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\pulki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pulki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pulki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What causes precipitation to fall?\n",
    "\n",
    "Passage:\n",
    "\n",
    "Sent1: In meteorology, precipitation is any product of the condensation of atmospheric water vapor.\n",
    "\n",
    "Sent2: Precipitation falls under the effect of gravity. \n",
    "\n",
    "Ans: [Gravity]\n",
    "\n",
    "Q2: What group in the Periodic table oxygen belongs?\n",
    "\n",
    "Passage:\n",
    "\n",
    "Sent1: Oxygen is a chemical element with symbol O and atomic number 8.\n",
    "\n",
    "Sent2: It is a member of the chalcogen group on the periodic table.\n",
    "\n",
    "Ans: [chalcogen]\n",
    "\n",
    "Q3: Who was the coach of Sachin Tendulakar?\n",
    "\n",
    "Passage:\n",
    "\n",
    "Sent1: Ramakant Vitthal Achrekar was a famous coach. \n",
    "\n",
    "Sent2: He was most famous for coaching young cricketers at Shivaji Park, most notably Sachin Tendulkar. \n",
    "\n",
    "Sent3: He had also been a selector for the Mumbai cricket team.\n",
    "\n",
    "Ans: [Ramakant Vitthal Achrekar, Vasu Paranjape, John Wright]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = 'What causes precipitation to fall?'.split()\n",
    "Q2 = 'What group in the Periodic table oxygen belongs?'.split()\n",
    "Q3 = 'Who was the coach of Sachin Tendulakar?'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage1 = [\n",
    "    'In meteorology, precipitation is any product of the condensation of atmospheric water vapor.'.split(),\n",
    "    'Precipitation falls under the effect of gravity.'.split()\n",
    "]\n",
    "\n",
    "passage2 = [\n",
    "    'Oxygen is a chemical element with symbol O and atomic number 8.'.split(),\n",
    "    'It is a member of the chalcogen group on the periodic table.'.split()\n",
    "]   \n",
    "\n",
    "passage3 = [\n",
    "    'Ramakant Vitthal Achrekar was a famous coach.'.split(),\n",
    "    'He was most famous for coaching young cricketers at Shivaji Park, most notably Sachin Tendulkar.'.split(),\n",
    "    'He had also been a selector for the Mumbai cricket team.'.split()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = ['Gravity']\n",
    "a2 = ['Chalcogen']\n",
    "a3 = ['Ramakant Vitthal Achrekar', 'Vasu Paranjape', 'John Wright']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Pre-Process a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_sentence(sentence):\n",
    "\n",
    "    # CHANGED - Not Doing Lower Case\n",
    "\n",
    "    # Sentence is a list of words\n",
    "    # Returns a list of words\n",
    "\n",
    "    # Remove all punctuations\n",
    "    sentence = [re.sub(r'[^\\w\\s]','',word) for word in sentence]\n",
    "\n",
    "    # # Convert all words to lower case\n",
    "    # sentence = [word.lower() for word in sentence]\n",
    "\n",
    "    # Return the sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'causes', 'precipitation', 'to', 'fall']\n",
      "['What', 'group', 'in', 'the', 'Periodic', 'table', 'oxygen', 'belongs']\n",
      "['Who', 'was', 'the', 'coach', 'of', 'Sachin', 'Tendulakar']\n"
     ]
    }
   ],
   "source": [
    "print(pre_process_sentence(Q1))\n",
    "print(pre_process_sentence(Q2))\n",
    "print(pre_process_sentence(Q3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Pre-Process a Passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_passage(passage):\n",
    "    # Passage is a list of sentences\n",
    "    # Returns a list of sentences\n",
    "\n",
    "    # Pre-process each sentence\n",
    "    passage = [pre_process_sentence(sentence) for sentence in passage]\n",
    "\n",
    "    # Return the passage\n",
    "    return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['In', 'meteorology', 'precipitation', 'is', 'any', 'product', 'of', 'the', 'condensation', 'of', 'atmospheric', 'water', 'vapor'], ['Precipitation', 'falls', 'under', 'the', 'effect', 'of', 'gravity']]\n"
     ]
    }
   ],
   "source": [
    "print(pre_process_passage(passage1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Oxygen', 'is', 'a', 'chemical', 'element', 'with', 'symbol', 'O', 'and', 'atomic', 'number', '8'], ['It', 'is', 'a', 'member', 'of', 'the', 'chalcogen', 'group', 'on', 'the', 'periodic', 'table']]\n"
     ]
    }
   ],
   "source": [
    "print(pre_process_passage(passage2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ramakant', 'Vitthal', 'Achrekar', 'was', 'a', 'famous', 'coach'], ['He', 'was', 'most', 'famous', 'for', 'coaching', 'young', 'cricketers', 'at', 'Shivaji', 'Park', 'most', 'notably', 'Sachin', 'Tendulkar'], ['He', 'had', 'also', 'been', 'a', 'selector', 'for', 'the', 'Mumbai', 'cricket', 'team']]\n"
     ]
    }
   ],
   "source": [
    "print(pre_process_passage(passage3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform POS tagging on the question and only extract the nouns and verbs (all tags starting with NN, VB except auxiliary verbs like is, was)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'causes', 'precipitation', 'to', 'fall']\n"
     ]
    }
   ],
   "source": [
    "q1_preprocessed = pre_process_sentence(Q1)\n",
    "q2_preprocessed = pre_process_sentence(Q2)\n",
    "q3_preprocessed = pre_process_sentence(Q3)\n",
    "\n",
    "print(q1_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform POS tagging on the question and only extract the nouns and verbs (all tags starting with NN, VB except auxiliary verbs like is, was)\n",
    "def get_nouns_verbs(question):\n",
    "    # Question is a list of words\n",
    "    # Returns a list of nouns and verbs\n",
    "\n",
    "    # Perform POS tagging\n",
    "    tagged = nltk.pos_tag(question)\n",
    "\n",
    "    # Extract only nouns and verbs (all tags starting with NN, VB except auxiliary verbs like is, was)\n",
    "    nouns_verbs = [word for word, tag in tagged if tag.startswith('NN') or tag.startswith('VB') and tag != 'VBD']\n",
    "\n",
    "    # Return the nouns and verbs\n",
    "    return nouns_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:\n",
      "['What', 'causes', 'precipitation', 'to', 'fall']\n",
      "['causes', 'precipitation', 'fall']\n",
      "Q2:\n",
      "['What', 'group', 'in', 'the', 'Periodic', 'table', 'oxygen', 'belongs']\n",
      "['group', 'Periodic', 'table', 'oxygen', 'belongs']\n",
      "Q3:\n",
      "['Who', 'was', 'the', 'coach', 'of', 'Sachin', 'Tendulakar']\n",
      "['coach', 'Sachin', 'Tendulakar']\n"
     ]
    }
   ],
   "source": [
    "q1_nouns_verbs = get_nouns_verbs(q1_preprocessed)\n",
    "q2_nouns_verbs = get_nouns_verbs(q2_preprocessed)\n",
    "q3_nouns_verbs = get_nouns_verbs(q3_preprocessed)\n",
    "\n",
    "print(\"Q1:\")\n",
    "print(q1_preprocessed)\n",
    "print(q1_nouns_verbs)\n",
    "\n",
    "print(\"Q2:\")\n",
    "print(q2_preprocessed)\n",
    "print(q2_nouns_verbs)\n",
    "\n",
    "print(\"Q3:\")\n",
    "print(q3_preprocessed)\n",
    "print(q3_nouns_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform POS tagging on the passage and do a coreference resolution. \n",
    "\n",
    "### Coreference Resolution is a technique to resolve the pronouns in a text. For example, in the passage above, the pronoun “he” refers to “Ramakant Vitthal Achrekar”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform POS tagging on the passage and do a coreference resolution. Coreference resolution is a task where we find out the proper nouns referred to by the pronouns. Here, you may adhere to a naive method where you replace a pronoun by the nearest “proper noun (NNP)” at the left side of it (it can go beyond sentence boundary). Alternatively, you may use a standard coreference resolution package in Python.\n",
    "\n",
    "# Performs Naive Coreference Resolution\n",
    "def get_coreference_resolved_passage(passage):\n",
    "    # Passage is a list of sentences\n",
    "    # Returns a list of sentences\n",
    "\n",
    "    # Pre-process the passage\n",
    "    passage = pre_process_passage(passage)\n",
    "\n",
    "    # Perform POS tagging\n",
    "    tagged = [nltk.pos_tag(sentence) for sentence in passage]\n",
    "\n",
    "    # Perform coreference resolution\n",
    "    # Replace all pronouns by the nearest proper noun at the left side of it\n",
    "    # It can go beyond sentence boundary\n",
    "    coref_resolved = []\n",
    "\n",
    "    cnt = 0\n",
    "    for cnt in range(len(tagged)):\n",
    "        \n",
    "        sentence = tagged[cnt]\n",
    "\n",
    "        coref_resolved_sentence = []\n",
    "\n",
    "        for i in range(len(sentence)):\n",
    "\n",
    "            if sentence[i][1] == 'PRP':\n",
    "                \n",
    "                # Check Noun at left in same sentence\n",
    "                noun_left = None\n",
    "                for j in range(i - 1, -1, -1):\n",
    "                    if sentence[j][1] == 'NNP':\n",
    "                        noun_left = sentence[j][0]\n",
    "                        break\n",
    "                \n",
    "                # Check Noun at left in previous sentence\n",
    "                if not noun_left and cnt > 0:\n",
    "                    for sent in tagged[cnt-1::-1]:\n",
    "\n",
    "                        for j in range(len(sent) - 1, -1, -1):\n",
    "                            if sent[j][1] == 'NNP':\n",
    "                                noun_left = sent[j][0]\n",
    "                                break\n",
    "                        \n",
    "                        if noun_left:\n",
    "                            break\n",
    "                \n",
    "                if noun_left:\n",
    "                    # Add the noun to the coref_resolved_sentence along with TAG\n",
    "                    coref_resolved_sentence.append((noun_left, 'NNP'))\n",
    "                else:\n",
    "                    # Add the word to the coref_resolved_sentence along with TAG\n",
    "                    coref_resolved_sentence.append((sentence[i][0], sentence[i][1]))\n",
    "\n",
    "            else:\n",
    "                # Add the word to the coref_resolved_sentence along with TAG\n",
    "                coref_resolved_sentence.append((sentence[i][0], sentence[i][1]))\n",
    "        \n",
    "        coref_resolved.append(coref_resolved_sentence)\n",
    "        \n",
    "    # Return the coreference resolved passage\n",
    "    return coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('In', 'IN'), ('meteorology', 'NN'), ('precipitation', 'NN'), ('is', 'VBZ'), ('any', 'DT'), ('product', 'NN'), ('of', 'IN'), ('the', 'DT'), ('condensation', 'NN'), ('of', 'IN'), ('atmospheric', 'JJ'), ('water', 'NN'), ('vapor', 'NN')], [('Precipitation', 'NN'), ('falls', 'VBZ'), ('under', 'IN'), ('the', 'DT'), ('effect', 'NN'), ('of', 'IN'), ('gravity', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Coreference resolution on passage 1 after pre-processing\n",
    "passage1_coref_resolved = get_coreference_resolved_passage(passage1)\n",
    "print(passage1_coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Oxygen', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('chemical', 'JJ'), ('element', 'NN'), ('with', 'IN'), ('symbol', 'NN'), ('O', 'NNP'), ('and', 'CC'), ('atomic', 'JJ'), ('number', 'NN'), ('8', 'CD')], [('O', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('member', 'NN'), ('of', 'IN'), ('the', 'DT'), ('chalcogen', 'NN'), ('group', 'NN'), ('on', 'IN'), ('the', 'DT'), ('periodic', 'NN'), ('table', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Coreference resolution on passage 2 after pre-processing\n",
    "passage2_coref_resolved = get_coreference_resolved_passage(passage2)\n",
    "print(passage2_coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Ramakant', 'JJ'), ('Vitthal', 'NNP'), ('Achrekar', 'NNP'), ('was', 'VBD'), ('a', 'DT'), ('famous', 'JJ'), ('coach', 'NN')], [('Achrekar', 'NNP'), ('was', 'VBD'), ('most', 'RBS'), ('famous', 'JJ'), ('for', 'IN'), ('coaching', 'VBG'), ('young', 'JJ'), ('cricketers', 'NNS'), ('at', 'IN'), ('Shivaji', 'NNP'), ('Park', 'NNP'), ('most', 'RBS'), ('notably', 'RB'), ('Sachin', 'NNP'), ('Tendulkar', 'NNP')], [('Tendulkar', 'NNP'), ('had', 'VBD'), ('also', 'RB'), ('been', 'VBN'), ('a', 'DT'), ('selector', 'NN'), ('for', 'IN'), ('the', 'DT'), ('Mumbai', 'NNP'), ('cricket', 'NN'), ('team', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Coreference resolution on passage 3 after pre-processing\n",
    "passage3_coref_resolved = get_coreference_resolved_passage(passage3)  \n",
    "print(passage3_coref_resolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the question terms and passage terms, such that words match even if they differ in case, tense, singular/plural etc\n",
    "\n",
    "### Find the sentence(s) from the passage which contains maximum overlap with the nouns and verbs extracted from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tokenizer and Lemmatizer from NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# After performing coreference resolution, find the sentence(s) from the passage which contains maximum overlap with the nouns and verbs extracted from the question. Before matching, please perform adequate normalization of both question terms and passage terms, such that words match even if they differ in case, tense, singular/plural etc\n",
    "def find_sentences_from_passage_with_maximum_overlap(passage, question):\n",
    "    # Passage is a list of sentences\n",
    "    # Question is a list of words\n",
    "    # Returns a list of sentences\n",
    "    best_sentences = []\n",
    "    best_score = 0\n",
    "\n",
    "    # Normalise the Question such that words match even if they differ in case, tense, singular/plural etc\n",
    "    question_lemmatized = [lemmatizer.lemmatize(word.lower()) for word in question]\n",
    "\n",
    "    # print(question)\n",
    "    \n",
    "    for sentence in passage:\n",
    "        \n",
    "        # Normalize the sentence such that words match even if they differ in case, tense, singular/plural etc\n",
    "        sentence_lemmatized = [lemmatizer.lemmatize(word.lower()) for word in sentence]\n",
    "\n",
    "        score = 0\n",
    "        for word in question_lemmatized:\n",
    "            if word in sentence:\n",
    "                score += 1\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_sentences = []\n",
    "            best_sentences.append(sentence.copy())\n",
    "            best_score = score\n",
    "        elif score == best_score:\n",
    "            best_sentences.append(sentence.copy())\n",
    "    \n",
    "    return best_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['causes', 'precipitation', 'fall']\n",
      "['group', 'Periodic', 'table', 'oxygen', 'belongs']\n",
      "['coach', 'Sachin', 'Tendulakar']\n"
     ]
    }
   ],
   "source": [
    "print(q1_nouns_verbs)\n",
    "print(q2_nouns_verbs)\n",
    "print(q3_nouns_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Passages, take only words and not tags\n",
    "passage1_coref_resolved_words = [[word for word, tag in sentence] for sentence in passage1_coref_resolved]\n",
    "passage2_coref_resolved_words = [[word for word, tag in sentence] for sentence in passage2_coref_resolved]\n",
    "passage3_coref_resolved_words = [[word for word, tag in sentence] for sentence in passage3_coref_resolved]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Sentences with Maximum Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage 1:\n",
      "[['In', 'meteorology', 'precipitation', 'is', 'any', 'product', 'of', 'the', 'condensation', 'of', 'atmospheric', 'water', 'vapor']]\n",
      "Passage 2:\n",
      "[['O', 'is', 'a', 'member', 'of', 'the', 'chalcogen', 'group', 'on', 'the', 'periodic', 'table']]\n",
      "Passage 3:\n",
      "[['Ramakant', 'Vitthal', 'Achrekar', 'was', 'a', 'famous', 'coach']]\n"
     ]
    }
   ],
   "source": [
    "# Find the sentence(s) from the passage which contains maximum overlap with the nouns and verbs extracted from the question\n",
    "\n",
    "# For Passage 1\n",
    "print(\"Passage 1:\")\n",
    "match_p1 = find_sentences_from_passage_with_maximum_overlap(passage1_coref_resolved_words, q1_nouns_verbs)\n",
    "print(match_p1)\n",
    "\n",
    "# For Passage 2\n",
    "print(\"Passage 2:\")\n",
    "match_p2 = find_sentences_from_passage_with_maximum_overlap(passage2_coref_resolved_words, q2_nouns_verbs)\n",
    "print(match_p2)\n",
    "\n",
    "# For Passage 3\n",
    "print(\"Passage 3:\")\n",
    "match_p3 = find_sentences_from_passage_with_maximum_overlap(passage3_coref_resolved_words, q3_nouns_verbs)\n",
    "print(match_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the noun phrases (combinations of consecutive nouns, adjectives and determiners) from the matched sentences excluding the words present in the question. \n",
    "\n",
    "## These noun phrases are the potential answers. \n",
    "\n",
    "## If multiple sentences happen to have the same overlap and that is the maximum, extract potential answers from all these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the noun phrases (combinations of consecutive nouns, adjectives and determiners) from the matched sentences excluding the words present in the question. These noun phrases are the potential answers. If multiple sentences happen to have the same overlap and that is the maximum, extract potential answers from all these sentences.\n",
    "def extract_potential_answers_from_sentences(sentences, question):\n",
    "    # Sentences is a list of sentences\n",
    "    # Question is a list of words\n",
    "    # Returns a list of potential answers\n",
    "    potential_answers = []\n",
    "\n",
    "    # Normalise the Question such that words match even if they differ in case, singular/plural etc\n",
    "    question_lemmatized = [lemmatizer.lemmatize(word.lower()) for word in question]\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        # Normalize the sentence such that words match even if they differ in case, singular/plural etc\n",
    "        sentence_lemmatized = [lemmatizer.lemmatize(word.lower()) for word in sentence]\n",
    "\n",
    "        # Extract Noun Phrases from the sentence\n",
    "        tagged = nltk.pos_tag(sentence_lemmatized)\n",
    "        chunkGram = r\"\"\"Chunk: {<DT>?<JJ>*<NN>}\"\"\"\n",
    "        chunkParser = nltk.RegexpParser(chunkGram)\n",
    "        chunked = chunkParser.parse(tagged)\n",
    "\n",
    "        # print(chunked)\n",
    "\n",
    "        for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "            potential_answer = [word for word, tag in subtree.leaves()]\n",
    "            if potential_answer not in potential_answers and potential_answer not in question_lemmatized:\n",
    "                potential_answers.append(potential_answer)\n",
    "    \n",
    "    return potential_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage 1:\n",
      "[['meteorology'], ['precipitation'], ['any', 'product'], ['the', 'condensation'], ['atmospheric', 'water'], ['vapor']]\n",
      "Passage 2:\n",
      "[['o'], ['a', 'member'], ['the', 'chalcogen'], ['group'], ['the', 'periodic'], ['table']]\n",
      "Passage 3:\n",
      "[['ramakant', 'vitthal'], ['achrekar'], ['a', 'famous', 'coach']]\n"
     ]
    }
   ],
   "source": [
    "# Extract the potential answers from the matched sentences\n",
    "\n",
    "# For Passage 1\n",
    "print(\"Passage 1:\")\n",
    "potential_answers_p1 = extract_potential_answers_from_sentences(match_p1, q1_nouns_verbs)\n",
    "print(potential_answers_p1)\n",
    "\n",
    "# For Passage 2\n",
    "print(\"Passage 2:\")\n",
    "potential_answers_p2 = extract_potential_answers_from_sentences(match_p2, q2_nouns_verbs)\n",
    "print(potential_answers_p2)\n",
    "\n",
    "# For Passage 3\n",
    "print(\"Passage 3:\")\n",
    "potential_answers_p3 = extract_potential_answers_from_sentences(match_p3, q3_nouns_verbs)\n",
    "print(potential_answers_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the extracted answers with the ground truth answer list. \n",
    "\n",
    "## Calculate precision (how many retrieved answers are correct) and recall (how many correct answers are retrieved). \n",
    "\n",
    "## Consider full match even if a retrieved answer partially matches with a ground truth answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the extracted answers with the ground truth answer list. Calculate precision (how many retrieved answers are correct) and recall (how many correct answers are retrieved). Consider full match even if a retrieved answer partially matches with a ground truth answer.\n",
    "def calculate_precision_recall(retrieved_answers, ground_truth_answers):\n",
    "    \n",
    "    print(\"Retrieved Answers: \", retrieved_answers)\n",
    "    print(\"Ground Truth Answers: \", ground_truth_answers)\n",
    "\n",
    "    # Normalise the retrieved answers such that words match even if they differ in case, singular/plural etc\n",
    "    retrieved_answers_lemmatized = [[lemmatizer.lemmatize(word.lower()) for word in answer] for answer in retrieved_answers]\n",
    "    \n",
    "    # Normalise the ground truth answers such that words match even if they differ in case, singular/plural etc\n",
    "    ground_truth_answers_lemmatized = [[lemmatizer.lemmatize(word.lower()) for word in answer] for answer in ground_truth_answers]\n",
    "\n",
    "    print(\"Lemmatized Retrieved Answers: \", retrieved_answers_lemmatized)\n",
    "    print(\"Lemmatized Ground Truth Answers: \", ground_truth_answers_lemmatized)\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    correct_answers = 0\n",
    "    for answer in retrieved_answers_lemmatized:\n",
    "        for real_answer in ground_truth_answers_lemmatized:\n",
    "            \n",
    "            real_answer = real_answer[0].split()\n",
    "\n",
    "            # Check Intersection\n",
    "            if set(answer).intersection(set(real_answer)):\n",
    "                correct_answers += 1\n",
    "                print(\"MATCH:\", answer, real_answer)\n",
    "                break\n",
    "    \n",
    "    precision = correct_answers / len(retrieved_answers_lemmatized)\n",
    "    print(\"Precision: \", precision)\n",
    "\n",
    "    recall = correct_answers / len(ground_truth_answers_lemmatized)\n",
    "    print(\"Recall: \", recall)\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_f = [[word] for word in a1]\n",
    "a2_f = [[word] for word in a2]\n",
    "a3_f = [[word] for word in a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Gravity']],\n",
       " [['Chalcogen']],\n",
       " [['Ramakant Vitthal Achrekar'], ['Vasu Paranjape'], ['John Wright']])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_f, a2_f, a3_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:\n",
      "Question: ['What', 'causes', 'precipitation', 'to', 'fall?']\n",
      "Retrieved Answers:  [['meteorology'], ['precipitation'], ['any', 'product'], ['the', 'condensation'], ['atmospheric', 'water'], ['vapor']]\n",
      "Ground Truth Answers:  [['Gravity']]\n",
      "Lemmatized Retrieved Answers:  [['meteorology'], ['precipitation'], ['any', 'product'], ['the', 'condensation'], ['atmospheric', 'water'], ['vapor']]\n",
      "Lemmatized Ground Truth Answers:  [['gravity']]\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Q1:\")\n",
    "print(\"Question:\", Q1)\n",
    "calculate_precision_recall(potential_answers_p1, a1_f)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2:\n",
      "Question: ['What', 'group', 'in', 'the', 'Periodic', 'table', 'oxygen', 'belongs?']\n",
      "Retrieved Answers:  [['o'], ['a', 'member'], ['the', 'chalcogen'], ['group'], ['the', 'periodic'], ['table']]\n",
      "Ground Truth Answers:  [['Chalcogen']]\n",
      "Lemmatized Retrieved Answers:  [['o'], ['a', 'member'], ['the', 'chalcogen'], ['group'], ['the', 'periodic'], ['table']]\n",
      "Lemmatized Ground Truth Answers:  [['chalcogen']]\n",
      "MATCH: ['the', 'chalcogen'] ['chalcogen']\n",
      "Precision:  0.16666666666666666\n",
      "Recall:  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Q2:\")\n",
    "print(\"Question:\", Q2)\n",
    "calculate_precision_recall(potential_answers_p2, a2_f)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3:\n",
      "Question: ['Who', 'was', 'the', 'coach', 'of', 'Sachin', 'Tendulakar?']\n",
      "Retrieved Answers:  [['ramakant', 'vitthal'], ['achrekar'], ['a', 'famous', 'coach']]\n",
      "Ground Truth Answers:  [['Ramakant Vitthal Achrekar'], ['Vasu Paranjape'], ['John Wright']]\n",
      "Lemmatized Retrieved Answers:  [['ramakant', 'vitthal'], ['achrekar'], ['a', 'famous', 'coach']]\n",
      "Lemmatized Ground Truth Answers:  [['ramakant vitthal achrekar'], ['vasu paranjape'], ['john wright']]\n",
      "MATCH: ['ramakant', 'vitthal'] ['ramakant', 'vitthal', 'achrekar']\n",
      "MATCH: ['achrekar'] ['ramakant', 'vitthal', 'achrekar']\n",
      "Precision:  0.6666666666666666\n",
      "Recall:  0.6666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Q3:\")\n",
    "print(\"Question:\", Q3)\n",
    "calculate_precision_recall(potential_answers_p3, a3_f)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a01861876d126b30cd1b77ced19e532f706bc03e1154ffd933be16f6f668bcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
